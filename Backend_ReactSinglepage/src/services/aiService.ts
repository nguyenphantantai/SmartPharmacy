import { config } from '../config/index.js';

// Lazy load AI clients to avoid errors if packages not installed
let openaiClient: any = null;
let geminiClient: any = null;

// Export initialization function for server startup
export async function initializeAIClients() {
  await initializeClients();
}

// Initialize clients on first use
async function initializeClients() {
  // Initialize OpenAI
  if (!openaiClient && process.env.OPENAI_API_KEY) {
    try {
      // Dynamic import to avoid errors if package not installed
      const openaiModule = await import('openai');
      const OpenAI = (openaiModule as any).default || openaiModule;
      openaiClient = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
      console.log('‚úÖ OpenAI initialized');
    } catch (error) {
      console.log('‚ö†Ô∏è OpenAI package not installed');
    }
  }

  // Initialize Gemini
  if (!geminiClient && process.env.GEMINI_API_KEY) {
    try {
      const { GoogleGenerativeAI } = await import('@google/generative-ai');
      geminiClient = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
      // Default to gemini-2.5-flash (stable and fast), user can override with GEMINI_MODEL
      const modelName = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
      console.log(`‚úÖ Google Gemini AI initialized (Model: ${modelName})`);
    } catch (error: any) {
      console.log('‚ö†Ô∏è Google Gemini package not installed or error:', error.message);
      console.log('   Run: npm install @google/generative-ai');
      console.log('   Add GEMINI_API_KEY to .env file');
    }
  } else if (!process.env.GEMINI_API_KEY) {
    console.log('‚ÑπÔ∏è GEMINI_API_KEY not found in environment variables');
  }
}

// Alternative: Use other AI services
// - Google Gemini API
// - Anthropic Claude API
// - Local LLM (Ollama, LM Studio)
// - Vietnamese LLM (VinAI, FPT AI)

interface AIChatOptions {
  userMessage: string;
  conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }>;
  context?: {
    medicines?: any[];
    userHistory?: any[];
    symptoms?: string[];
  };
}

/**
 * Generate AI response using OpenAI GPT
 * Fallback to rule-based system if API key not configured
 */
export async function generateAIResponseWithLLM(options: AIChatOptions): Promise<string> {
  const { userMessage, conversationHistory, context } = options;

  // Initialize if not already done
  await initializeClients();

  // If OpenAI is not configured, return null to use rule-based system
  if (!openaiClient) {
    return null as any; // Signal to use fallback
  }

  try {
    // Build system prompt for pharmacy assistant
    const systemPrompt = `B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp c·ªßa Nh√† Thu·ªëc Th√¥ng Minh. Nhi·ªám v·ª• c·ªßa b·∫°n:

1. **Hi·ªÉu ƒë√∫ng ng·ªØ c·∫£nh**: Ph√¢n t√≠ch ch√≠nh x√°c y√™u c·∫ßu c·ªßa kh√°ch h√†ng v√† ch·ªâ g·ª£i √Ω thu·ªëc PH√ô H·ª¢P v·ªõi tri·ªáu ch·ª©ng/b·ªánh h·ªç ƒë·ªÅ c·∫≠p. KH√îNG BAO GI·ªú g·ª£i √Ω thu·ªëc kh√¥ng li√™n quan.

2. **H·ªèi th√™m tri·ªáu ch·ª©ng**: Khi kh√°ch h√†ng y√™u c·∫ßu thu·ªëc chung chung (v√≠ d·ª•: "thu·ªëc c·∫£m"), b·∫°n N√äN h·ªèi th√™m 1-2 c√¢u v·ªÅ tri·ªáu ch·ª©ng c·ª• th·ªÉ (ho, ngh·∫πt m≈©i, s·ªët, ƒëau h·ªçng...) tr∆∞·ªõc khi g·ª£i √Ω thu·ªëc.

3. **G·ª£i √Ω thu·ªëc ch√≠nh x√°c**:
   - Ch·ªâ g·ª£i √Ω 3-5 thu·ªëc ph√π h·ª£p nh·∫•t (KH√îNG qu√° nhi·ªÅu)
   - ∆Øu ti√™n thu·ªëc OTC (kh√¥ng c·∫ßn ƒë∆°n b√°c sƒ©)
   - Ph√¢n lo·∫°i theo nh√≥m: h·∫° s·ªët-gi·∫£m ƒëau, c·∫£m t·ªïng h·ª£p, long ƒë·ªùm, ho khan, v.v.
   - KH√îNG g·ª£i √Ω thu·ªëc kh√¥ng li√™n quan (v√≠ d·ª•: h·ªèi c·∫£m nh∆∞ng g·ª£i √Ω probiotics, thu·ªëc ho tr·∫ª em)

4. **Format chuy√™n nghi·ªáp khi g·ª£i √Ω thu·ªëc**:
   - S·ª≠ d·ª•ng format sau cho m·ªói thu·ªëc:
     ```
     [S·ªë]. **[T√™n thu·ªëc]**
     üí∞ Gi√°: [gi√°]ƒë
     üíä T√°c d·ª•ng: [m√¥ t·∫£ c√¥ng d·ª•ng r√µ r√†ng, KH√îNG ph·∫£i h√†m l∆∞·ª£ng]
     üì¶ Quy c√°ch: [ƒë∆°n v·ªã/quy c√°ch]
     ```
   - QUAN TR·ªåNG: Tr∆∞·ªùng "T√°c d·ª•ng" ph·∫£i l√† m√¥ t·∫£ c√¥ng d·ª•ng (v√≠ d·ª•: "H·∫° s·ªët, gi·∫£m ƒëau nh·∫π"), KH√îNG ƒë∆∞·ª£c ghi h√†m l∆∞·ª£ng (v√≠ d·ª•: "500mg" l√† SAI)

5. **Th√¥ng tin ch√≠nh x√°c**: 
   - S·ª≠ d·ª•ng th√¥ng tin t·ª´ context (danh s√°ch thu·ªëc ƒë∆∞·ª£c cung c·∫•p)
   - N·∫øu kh√¥ng c√≥ th√¥ng tin, n√≥i r√µ "Vui l√≤ng li√™n h·ªá d∆∞·ª£c sƒ©"

6. **C·∫£nh b√°o an to√†n**:
   - Lu√¥n c·∫£nh b√°o: "‚ö†Ô∏è ƒê√¢y ch·ªâ l√† t∆∞ v·∫•n tham kh·∫£o. Vui l√≤ng h·ªèi d∆∞·ª£c sƒ© tr∆∞·ªõc khi d√πng."
   - C·∫£nh b√°o ngay khi ph√°t hi·ªán t√¨nh tr·∫°ng nghi√™m tr·ªçng (s·ªët cao >39¬∞C, ƒëau ng·ª±c, kh√≥ th·ªü...)

7. **Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp**

QUAN TR·ªåNG:
- KH√îNG ƒë∆∞·ª£c thay th·∫ø ch·ªâ ƒë·ªãnh c·ªßa b√°c sƒ©
- Lu√¥n khuy·∫øn kh√≠ch tham kh·∫£o √Ω ki·∫øn d∆∞·ª£c sƒ©/b√°c sƒ©
- KH√îNG b√°n kh√°ng sinh kh√¥ng c·∫ßn ƒë∆°n
- Ch·ªâ g·ª£i √Ω thu·ªëc OTC (kh√¥ng c·∫ßn ƒë∆°n b√°c sƒ©)
- Hi·ªÉu ƒë√∫ng ng·ªØ c·∫£nh: N·∫øu kh√°ch h·ªèi "thu·ªëc c·∫£m" ‚Üí ch·ªâ g·ª£i √Ω thu·ªëc c·∫£m, KH√îNG g·ª£i √Ω thu·ªëc kh√°c`;

    // Build context information
    let contextInfo = '';
    if (context?.medicines && context.medicines.length > 0) {
      contextInfo += `\n\nTh√¥ng tin thu·ªëc c√≥ s·∫µn trong h·ªá th·ªëng (ch·ªâ g·ª£i √Ω 3-5 thu·ªëc ph√π h·ª£p nh·∫•t):\n`;
      // Limit to 5 medicines max, prioritize by relevance
      context.medicines.slice(0, 5).forEach((med, idx) => {
        contextInfo += `${idx + 1}. ${med.name}`;
        // QUAN TR·ªåNG: Ch·ªâ hi·ªÉn th·ªã c√¥ng d·ª•ng (indication), KH√îNG hi·ªÉn th·ªã h√†m l∆∞·ª£ng ·ªü ƒë√¢y
        if (med.indication) {
          // Truncate long indications
          const shortIndication = med.indication.length > 200 
            ? med.indication.substring(0, 200) + '...' 
            : med.indication;
          contextInfo += `\n   - T√°c d·ª•ng: ${shortIndication}`;
        }
        if (med.strength) {
          contextInfo += `\n   - H√†m l∆∞·ª£ng: ${med.strength}`;
        }
        if (med.price) {
          contextInfo += `\n   - Gi√°: ${med.price.toLocaleString('vi-VN')}ƒë`;
        }
        if (med.unit) {
          contextInfo += `\n   - Quy c√°ch: ${med.unit}`;
        }
        contextInfo += '\n';
      });
      contextInfo += `\nL∆ØU √ù: Khi g·ª£i √Ω thu·ªëc, b·∫°n PH·∫¢I s·ª≠ d·ª•ng tr∆∞·ªùng "T√°c d·ª•ng" (kh√¥ng ph·∫£i h√†m l∆∞·ª£ng) trong ph·∫ßn m√¥ t·∫£ c√¥ng d·ª•ng c·ªßa thu·ªëc.\n`;
    }

    if (context?.symptoms && context.symptoms.length > 0) {
      contextInfo += `\nTri·ªáu ch·ª©ng ng∆∞·ªùi d√πng ƒë√£ ƒë·ªÅ c·∫≠p: ${context.symptoms.join(', ')}\n`;
      contextInfo += `H√£y ch·ªâ g·ª£i √Ω thu·ªëc PH√ô H·ª¢P v·ªõi c√°c tri·ªáu ch·ª©ng n√†y.\n`;
    }

    // Build messages for OpenAI
    const messages: any[] = [
      {
        role: 'system',
        content: systemPrompt + contextInfo
      },
      ...conversationHistory.map(msg => ({
        role: msg.role === 'user' ? 'user' : 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: userMessage
      }
    ];

    // Call OpenAI API
    const completion = await openaiClient.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4o-mini', // Use gpt-4o-mini for cost efficiency, or gpt-4o for better quality
      messages: messages,
      temperature: 0.7,
      max_tokens: 1000,
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0,
    });

    const aiResponse = completion.choices[0]?.message?.content || '';
    return aiResponse;

  } catch (error) {
    console.error('Error calling OpenAI API:', error);
    // Fallback to rule-based system on error
    return null as any;
  }
}

/**
 * Generate AI response using Google Gemini API
 * Free tier: 15 requests per minute, 1500 requests per day
 */
export async function generateAIResponseWithGemini(options: AIChatOptions): Promise<string> {
  const { userMessage, conversationHistory, context } = options;

  // Initialize if not already done
  await initializeClients();

  // If Gemini is not configured, return null to use rule-based system
  if (!geminiClient) {
    return null as any; // Signal to use fallback
  }

  try {
    // Get model (default: gemini-2.5-flash for stable and fast API)
    // Available models: gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash, gemini-flash-latest
    // Note: Older models (gemini-pro, gemini-1.5-flash) are deprecated
    let modelName: string = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
    
    // Map old model names to new ones
    const modelMapping: { [key: string]: string } = {
      'gemini-pro': 'gemini-pro-latest',
      'gemini-1.5-flash': 'gemini-2.5-flash',
      'gemini-1.5-pro': 'gemini-2.5-pro',
      'gemini-1.5-flash-latest': 'gemini-2.5-flash'
    };
    
    if (modelName && modelMapping[modelName]) {
      modelName = modelMapping[modelName];
    }
    
    const model = geminiClient.getGenerativeModel({ model: modelName });

    // Build system instruction for pharmacy assistant
    const systemInstruction = `B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp c·ªßa Nh√† Thu·ªëc Th√¥ng Minh. Nhi·ªám v·ª• c·ªßa b·∫°n:

1. **Hi·ªÉu ƒë√∫ng ng·ªØ c·∫£nh**: Ph√¢n t√≠ch ch√≠nh x√°c y√™u c·∫ßu c·ªßa kh√°ch h√†ng v√† ch·ªâ g·ª£i √Ω thu·ªëc PH√ô H·ª¢P v·ªõi tri·ªáu ch·ª©ng/b·ªánh h·ªç ƒë·ªÅ c·∫≠p. KH√îNG BAO GI·ªú g·ª£i √Ω thu·ªëc kh√¥ng li√™n quan.

2. **H·ªèi th√™m tri·ªáu ch·ª©ng**: Khi kh√°ch h√†ng y√™u c·∫ßu thu·ªëc chung chung (v√≠ d·ª•: "thu·ªëc c·∫£m"), b·∫°n N√äN h·ªèi th√™m 1-2 c√¢u v·ªÅ tri·ªáu ch·ª©ng c·ª• th·ªÉ (ho, ngh·∫πt m≈©i, s·ªët, ƒëau h·ªçng...) tr∆∞·ªõc khi g·ª£i √Ω thu·ªëc.

3. **G·ª£i √Ω thu·ªëc ch√≠nh x√°c**:
   - Ch·ªâ g·ª£i √Ω 3-5 thu·ªëc ph√π h·ª£p nh·∫•t (KH√îNG qu√° nhi·ªÅu)
   - ∆Øu ti√™n thu·ªëc OTC (kh√¥ng c·∫ßn ƒë∆°n b√°c sƒ©)
   - Ph√¢n lo·∫°i theo nh√≥m: h·∫° s·ªët-gi·∫£m ƒëau, c·∫£m t·ªïng h·ª£p, long ƒë·ªùm, ho khan, v.v.
   - KH√îNG g·ª£i √Ω thu·ªëc kh√¥ng li√™n quan (v√≠ d·ª•: h·ªèi c·∫£m nh∆∞ng g·ª£i √Ω probiotics, thu·ªëc ho tr·∫ª em)

4. **Format chuy√™n nghi·ªáp khi g·ª£i √Ω thu·ªëc**:
   - S·ª≠ d·ª•ng format sau cho m·ªói thu·ªëc:
     ```
     [S·ªë]. **[T√™n thu·ªëc]**
     üí∞ Gi√°: [gi√°]ƒë
     üíä T√°c d·ª•ng: [m√¥ t·∫£ c√¥ng d·ª•ng r√µ r√†ng, KH√îNG ph·∫£i h√†m l∆∞·ª£ng]
     üì¶ Quy c√°ch: [ƒë∆°n v·ªã/quy c√°ch]
     ```
   - QUAN TR·ªåNG: Tr∆∞·ªùng "T√°c d·ª•ng" ph·∫£i l√† m√¥ t·∫£ c√¥ng d·ª•ng (v√≠ d·ª•: "H·∫° s·ªët, gi·∫£m ƒëau nh·∫π"), KH√îNG ƒë∆∞·ª£c ghi h√†m l∆∞·ª£ng (v√≠ d·ª•: "500mg" l√† SAI)

5. **Th√¥ng tin ch√≠nh x√°c**: 
   - S·ª≠ d·ª•ng th√¥ng tin t·ª´ context (danh s√°ch thu·ªëc ƒë∆∞·ª£c cung c·∫•p)
   - N·∫øu kh√¥ng c√≥ th√¥ng tin, n√≥i r√µ "Vui l√≤ng li√™n h·ªá d∆∞·ª£c sƒ©"

6. **C·∫£nh b√°o an to√†n**:
   - Lu√¥n c·∫£nh b√°o: "‚ö†Ô∏è ƒê√¢y ch·ªâ l√† t∆∞ v·∫•n tham kh·∫£o. Vui l√≤ng h·ªèi d∆∞·ª£c sƒ© tr∆∞·ªõc khi d√πng."
   - C·∫£nh b√°o ngay khi ph√°t hi·ªán t√¨nh tr·∫°ng nghi√™m tr·ªçng (s·ªët cao >39¬∞C, ƒëau ng·ª±c, kh√≥ th·ªü...)

7. **Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp**

QUAN TR·ªåNG:
- KH√îNG ƒë∆∞·ª£c thay th·∫ø ch·ªâ ƒë·ªãnh c·ªßa b√°c sƒ©
- Lu√¥n khuy·∫øn kh√≠ch tham kh·∫£o √Ω ki·∫øn d∆∞·ª£c sƒ©/b√°c sƒ©
- KH√îNG b√°n kh√°ng sinh kh√¥ng c·∫ßn ƒë∆°n
- Ch·ªâ g·ª£i √Ω thu·ªëc OTC (kh√¥ng c·∫ßn ƒë∆°n b√°c sƒ©)
- Hi·ªÉu ƒë√∫ng ng·ªØ c·∫£nh: N·∫øu kh√°ch h·ªèi "thu·ªëc c·∫£m" ‚Üí ch·ªâ g·ª£i √Ω thu·ªëc c·∫£m, KH√îNG g·ª£i √Ω thu·ªëc kh√°c`;

    // Build context information
    let contextInfo = '';
    if (context?.medicines && context.medicines.length > 0) {
      contextInfo += `\n\nTh√¥ng tin thu·ªëc c√≥ s·∫µn trong h·ªá th·ªëng (ch·ªâ g·ª£i √Ω 3-5 thu·ªëc ph√π h·ª£p nh·∫•t):\n`;
      // Limit to 5 medicines max, prioritize by relevance
      context.medicines.slice(0, 5).forEach((med, idx) => {
        contextInfo += `${idx + 1}. ${med.name}`;
        // QUAN TR·ªåNG: Ch·ªâ hi·ªÉn th·ªã c√¥ng d·ª•ng (indication), KH√îNG hi·ªÉn th·ªã h√†m l∆∞·ª£ng ·ªü ƒë√¢y
        if (med.indication) {
          // Truncate long indications
          const shortIndication = med.indication.length > 200 
            ? med.indication.substring(0, 200) + '...' 
            : med.indication;
          contextInfo += `\n   - T√°c d·ª•ng: ${shortIndication}`;
        }
        if (med.strength) {
          contextInfo += `\n   - H√†m l∆∞·ª£ng: ${med.strength}`;
        }
        if (med.price) {
          contextInfo += `\n   - Gi√°: ${med.price.toLocaleString('vi-VN')}ƒë`;
        }
        if (med.unit) {
          contextInfo += `\n   - Quy c√°ch: ${med.unit}`;
        }
        if (med.stockQuantity) {
          contextInfo += `\n   - T·ªìn kho: ${med.stockQuantity} ${med.unit || 's·∫£n ph·∫©m'}`;
        }
        contextInfo += '\n';
      });
      contextInfo += `\nL∆ØU √ù: Khi g·ª£i √Ω thu·ªëc, b·∫°n PH·∫¢I s·ª≠ d·ª•ng tr∆∞·ªùng "T√°c d·ª•ng" (kh√¥ng ph·∫£i h√†m l∆∞·ª£ng) trong ph·∫ßn m√¥ t·∫£ c√¥ng d·ª•ng c·ªßa thu·ªëc.\n`;
    }

    if (context?.symptoms && context.symptoms.length > 0) {
      contextInfo += `\nTri·ªáu ch·ª©ng ng∆∞·ªùi d√πng ƒë√£ ƒë·ªÅ c·∫≠p: ${context.symptoms.join(', ')}\n`;
      contextInfo += `H√£y ch·ªâ g·ª£i √Ω thu·ªëc PH√ô H·ª¢P v·ªõi c√°c tri·ªáu ch·ª©ng n√†y.\n`;
    }

    if (context?.userHistory && context.userHistory.length > 0) {
      contextInfo += `\nL·ªãch s·ª≠ mua h√†ng c·ªßa ng∆∞·ªùi d√πng:\n`;
      context.userHistory.slice(0, 3).forEach((item, idx) => {
        contextInfo += `${idx + 1}. ${item.productName}\n`;
      });
    }

    // Build conversation history for Gemini
    // Gemini requires: first message must be from 'user', not 'model'
    // Format: parts array with text
    const chatHistory: any[] = [];
    
    // Filter and add conversation history
    // Skip if history starts with 'assistant' (model) - Gemini doesn't allow this
    let skipFirst = false;
    if (conversationHistory.length > 0 && conversationHistory[0]?.role === 'assistant') {
      skipFirst = true;
    }
    
    for (let i = 0; i < conversationHistory.length; i++) {
      const msg = conversationHistory[i];
      
      // Skip if message is undefined
      if (!msg) {
        continue;
      }
      
      // Skip first message if it's from assistant
      if (i === 0 && skipFirst) {
        continue;
      }
      
      if (msg.role === 'user') {
        chatHistory.push({
          role: 'user',
          parts: [{ text: msg.content }]
        });
      } else if (msg.role === 'assistant') {
        chatHistory.push({
          role: 'model',
          parts: [{ text: msg.content }]
        });
      }
    }

    // Start chat session
    // systemInstruction must be an object with parts array, not a string
    const fullSystemInstruction = systemInstruction + contextInfo;
    const chat = model.startChat({
      history: chatHistory.length > 0 ? chatHistory : undefined, // Only include if not empty
      systemInstruction: {
        parts: [{ text: fullSystemInstruction }]
      },
      generationConfig: {
        temperature: 0.7,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 4096, // Increased to prevent response truncation
      },
    });

    // Send user message
    const result = await chat.sendMessage(userMessage);
    const response = await result.response;
    let aiResponse = response.text();
    
    // Check if response was truncated (ends abruptly)
    // Gemini sometimes truncates if maxOutputTokens is reached
    if (aiResponse && aiResponse.length > 0) {
      console.log(`‚úÖ Gemini response received (${aiResponse.length} characters)`);
      
      // If response seems incomplete (ends mid-sentence), log a warning
      const lastChar = aiResponse.trim().slice(-1);
      if (!['.', '!', '?', ':', ';'].includes(lastChar) && aiResponse.length > 1000) {
        console.log('‚ö†Ô∏è Response might be truncated (does not end with punctuation)');
      }
    }

    return aiResponse;

  } catch (error: any) {
    console.error('Error calling Gemini API:', error);
    
    // Handle rate limit errors
    if (error.message?.includes('429') || error.message?.includes('quota')) {
      console.log('‚ö†Ô∏è Gemini API rate limit reached, falling back to rule-based system');
    }
    
    // Fallback to rule-based system on error
    return null as any;
  }
}

/**
 * Generate AI response using Anthropic Claude API (Alternative)
 */
export async function generateAIResponseWithClaude(options: AIChatOptions): Promise<string> {
  // Implementation for Anthropic Claude API
  // Requires: npm install @anthropic-ai/sdk
  // import Anthropic from '@anthropic-ai/sdk';
  // const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
  // ...
  return null as any;
}

/**
 * Generate AI response using local LLM (Ollama) - Free alternative
 */
export async function generateAIResponseWithOllama(options: AIChatOptions): Promise<string> {
  try {
    const ollamaUrl = process.env.OLLAMA_URL || 'http://localhost:11434';
    const model = process.env.OLLAMA_MODEL || 'llama3.2:3b'; // or 'mistral', 'phi3', etc.

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'system',
            content: 'B·∫°n l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ d∆∞·ª£c ph·∫©m. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ch√≠nh x√°c v√† an to√†n.'
          },
          ...options.conversationHistory,
          { role: 'user', content: options.userMessage }
        ],
        stream: false
      })
    });

    if (!response.ok) {
      return null as any;
    }

    const data = await response.json();
    return data.message?.content || null as any;
  } catch (error) {
    console.error('Error calling Ollama:', error);
    return null as any;
  }
}

